{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xni/vision/torchvision/io/_video_opt.py:17: UserWarning: video reader based on ffmpeg c++ ops not available\n",
      "  warnings.warn(\"video reader based on ffmpeg c++ ops not available\")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST(root=\"/Users/xni/Documents/pytorch_task/\",download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FCB394E5910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat = Image.open(\"/Users/xni/Documents/pytorch_task/cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_hue(img, hue_factor):\n",
    "    \"\"\"Adjust hue of an image.\n",
    "\n",
    "    The image hue is adjusted by converting the image to HSV and\n",
    "    cyclically shifting the intensities in the hue channel (H).\n",
    "    The image is then converted back to original image mode.\n",
    "\n",
    "    `hue_factor` is the amount of shift in H channel and must be in the\n",
    "    interval `[-0.5, 0.5]`.\n",
    "\n",
    "    See `Hue`_ for more details.\n",
    "\n",
    "    .. _Hue: https://en.wikipedia.org/wiki/Hue\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be adjusted.\n",
    "        hue_factor (float):  How much to shift the hue channel. Should be in\n",
    "            [-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel in\n",
    "            HSV space in positive and negative direction respectively.\n",
    "            0 means no shift. Therefore, both -0.5 and 0.5 will give an image\n",
    "            with complementary colors while 0 gives the original image.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Hue adjusted image.\n",
    "    \"\"\"\n",
    "    if not(-0.5 <= hue_factor <= 0.5):\n",
    "        raise ValueError('hue_factor is not in [-0.5, 0.5].'.format(hue_factor))\n",
    "\n",
    "#     if not _is_pil_image(img):\n",
    "#         raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    input_mode = img.mode\n",
    "    if input_mode in {'L', '1', 'I', 'F'}:\n",
    "        return img\n",
    "\n",
    "    h, s, v = img.convert('HSV').split()\n",
    "    print(h,s, v)\n",
    "    np_h = np.array(h, dtype=np.uint8)\n",
    "    # uint8 addition take cares of rotation across boundaries\n",
    "    with np.errstate(over='ignore'):\n",
    "        np_h += np.uint8(hue_factor * 255)\n",
    "    h = Image.fromarray(np_h, 'L')\n",
    "    img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=838x559 at 0x7FCB3985E490> <PIL.Image.Image image mode=L size=838x559 at 0x7FCB3985EE10> <PIL.Image.Image image mode=L size=838x559 at 0x7FCB3985E9D0>\n"
     ]
    }
   ],
   "source": [
    "img_new = adjust_hue(img_cat, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "img_cat = transform(img_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 559, 838])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cat.shape # CHW -> NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 559, 838])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cat = img_cat.unsqueeze(0)\n",
    "img_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2157, 0.2118, 0.2667])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cat[0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def hsv2rgb(h, s, v):\n",
    "    h = float(h)\n",
    "    s = float(s)\n",
    "    v = float(v)\n",
    "    h60 = h / 60.0\n",
    "    h60f = math.floor(h60)\n",
    "    hi = int(h60f) % 6\n",
    "    f = h60 - h60f\n",
    "    p = v * (1 - s)\n",
    "    q = v * (1 - f * s)\n",
    "    t = v * (1 - (1 - f) * s)\n",
    "    r, g, b = 0, 0, 0\n",
    "    if hi == 0: r, g, b = v, t, p\n",
    "    elif hi == 1: r, g, b = q, v, p\n",
    "    elif hi == 2: r, g, b = p, v, t\n",
    "    elif hi == 3: r, g, b = p, q, v\n",
    "    elif hi == 4: r, g, b = t, p, v\n",
    "    elif hi == 5: r, g, b = v, p, q\n",
    "    r, g, b = int(r * 255), int(g * 255), int(b * 255)\n",
    "    return r, g, b\n",
    "\n",
    "def rgb2hsv(r, g, b):\n",
    "    r, g, b = r/255.0, g/255.0, b/255.0\n",
    "    mx = max(r, g, b)\n",
    "    mn = min(r, g, b)\n",
    "    df = mx-mn\n",
    "    if mx == mn:\n",
    "        h = 0\n",
    "    elif mx == r:\n",
    "        h = (60 * ((g-b)/df) + 360) % 360\n",
    "    elif mx == g:\n",
    "        h = (60 * ((b-r)/df) + 120) % 360\n",
    "    elif mx == b:\n",
    "        h = (60 * ((r-g)/df) + 240) % 360\n",
    "    if mx == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = df/mx\n",
    "    v = mx\n",
    "    return h, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 559, 838])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
