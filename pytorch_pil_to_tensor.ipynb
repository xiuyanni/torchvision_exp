{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "    \n",
    "\n",
    "def _is_pil_image(img):\n",
    "    if accimage is not None:\n",
    "        return isinstance(img, (Image.Image, accimage.Image))\n",
    "    else:\n",
    "        return isinstance(img, Image.Image)\n",
    "    \n",
    "    \n",
    "def _rgb2hsv(testing):\n",
    "    max_vals, _ = torch.max(testing, dim=0)\n",
    "    min_vals, _ = torch.min(testing, dim=0)\n",
    "    v = max_vals\n",
    "    s = (max_vals - min_vals) / max_vals\n",
    "    df = max_vals - min_vals\n",
    "    r, g, b = testing[0], testing[1], testing[2]\n",
    "    \n",
    "    \n",
    "    h = max_vals != min_vals\n",
    "    hr =  (max_vals == r) * ((g - b) / df) \n",
    "    hg =  (max_vals == g) * ((b - r) / df + 2.0)\n",
    "    hb =  (max_vals == b) * ((r - g) / df + 4.0)    \n",
    "    h = h * (hr + hg + hb)\n",
    "    h = (h / 6.0) % 1.0\n",
    "    h[h != h] = 0\n",
    "    return torch.stack((h, s, v))\n",
    " \n",
    "def _hsv2rgb(testing):\n",
    "    h, s, v = testing[0], testing[1], testing[2]\n",
    "    i = (h * 6.0).type(torch.IntTensor)\n",
    "    f = (h * 6.0) - i\n",
    "    p = v * (1.0 - s)\n",
    "    q = v * (1.0 - f * s)\n",
    "    t = v * (1.0 - (1 - f) * s)\n",
    "    i = i % 6\n",
    "    r = (i == 0) * v + (i == 1) * q +  (i == 2) * p + (i == 3) * p + (i == 4) * t + (i == 5) * v \n",
    "    g = (i == 0) * t + (i == 1) * v +  (i == 2) * v + (i == 3) * q + (i == 4) * p + (i == 5) * p\n",
    "    b = (i == 0) * p + (i == 1) * p +  (i == 2) * t + (i == 3) * v + (i == 4) * v + (i == 5) * q\n",
    "    return torch.stack((r, g, b))\n",
    "    \n",
    "def adjust_hue2(img, hue_factor):\n",
    "    \"\"\"Adjust hue of an image.\n",
    "\n",
    "    The image hue is adjusted by converting the image to HSV and\n",
    "    cyclically shifting the intensities in the hue channel (H).\n",
    "    The image is then converted back to original image mode.\n",
    "\n",
    "    `hue_factor` is the amount of shift in H channel and must be in the\n",
    "    interval `[-0.5, 0.5]`.\n",
    "\n",
    "    See `Hue`_ for more details.\n",
    "\n",
    "    .. _Hue: https://en.wikipedia.org/wiki/Hue\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image or torch.Tensor): Image to be adjusted.\n",
    "                                         Input can be PIL or torch.Tensor.\n",
    "        hue_factor (float):  How much to shift the hue channel. Should be in\n",
    "            [-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel in\n",
    "            HSV space in positive and negative direction respectively.\n",
    "            0 means no shift. Therefore, both -0.5 and 0.5 will give an image\n",
    "            with complementary colors while 0 gives the original image.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image or torch.Tensor: Hue adjusted image.\n",
    "        If input is PIL Image, return PIL Image\n",
    "        If input is torch.Tensor, return torch.Tensor\n",
    "    \"\"\"\n",
    "    if not(-0.5 <= hue_factor <= 0.5):\n",
    "        raise ValueError('hue_factor is not in [-0.5, 0.5].'.format(hue_factor))\n",
    "    \n",
    "    if not _is_pil_image(img) and type(img) is not torch.Tensor:\n",
    "        raise TypeError('img should be PIL Image or torch.Tensor. Got {}'.format(type(img)))\n",
    "        \n",
    "    if _is_pil_image(img):\n",
    "        print(\"pil working\")\n",
    "\n",
    "        input_mode = img.mode\n",
    "        if input_mode in {'L', '1', 'I', 'F'}:\n",
    "            return img\n",
    "\n",
    "        h, s, v = img.convert('HSV').split()\n",
    "        tmp_h = transform(h)\n",
    "        np_h = np.array(h, dtype=np.uint8)\n",
    "        # uint8 addition take cares of rotation across boundaries\n",
    "        with np.errstate(over='ignore'):\n",
    "            np_h += np.uint8(hue_factor * 255)\n",
    "        h = Image.fromarray(np_h, 'L')\n",
    "        tmp = transform(h)\n",
    "        img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
    "        \n",
    "        return img\n",
    "    else:\n",
    "        assert type(img) is torch.Tensor\n",
    "        assert len(img.shape) == 3 # input img must be 3D torch.Tensor\n",
    "        assert img.shape[0] == 3 # input img must have 3 channels \n",
    "        # the default ToTensor in torchvision scale the RGB from [0,255] to [0, 1]\n",
    "        img = _rgb2hsv(img)\n",
    "        h, s, v = img[0], img[1], img[2]\n",
    "        new_h = h * 255\n",
    "        new_h = (new_h).type(torch.IntTensor)\n",
    "        new_h += int(hue_factor * 255)\n",
    "\n",
    "        new_h = new_h.type(torch.FloatTensor)\n",
    "        new_h = new_h / 255.0\n",
    "        new_img = _hsv2rgb(torch.stack((new_h, s, v)))\n",
    "        return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a new image\n",
    "img_cat = Image.open(\"/Users/xni/Documents/pytorch_task/cat.jpg\")\n",
    "# img_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pil working\n"
     ]
    }
   ],
   "source": [
    "# use the old adjust_hue \n",
    "# when input is PIL image, we use the old adjust_hue\n",
    "img_new = adjust_hue2(img_cat, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image adjusted using old method\n",
    "# img_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 559, 838])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the image into torch.Tensor\n",
    "transform = transforms.ToTensor()\n",
    "img_cat_tensor = transform(img_cat)\n",
    "img_cat_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the new adjust_hue\n",
    "# when input is torch.Tensor, we use the new adjust_hue\n",
    "new_cat = adjust_hue2(img_cat_tensor, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the image back into PIL image\n",
    "transform2 = transforms.ToPILImage()\n",
    "img_cal_pil = transform2(new_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image adjusted using new method\n",
    "\n",
    "# img_cal_pil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester(unittest.TestCase):\n",
    "    def test_adjust_hue(self):\n",
    "        x_shape = [2, 2, 3]\n",
    "        x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n",
    "        x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n",
    "        x_pil = Image.fromarray(x_np, mode='RGB')\n",
    "        \n",
    "        transform = transforms.ToTensor()\n",
    "        x_tensor = transform(x_pil)\n",
    "        with self.assertRaises(ValueError):\n",
    "            F.adjust_hue(x_pil, -0.7)\n",
    "            F.adjust_hue(x_pil, 1)\n",
    "            \n",
    "            adjust_hue2(x_tensor, -0.7)\n",
    "            adjust_hue2(x_tensor, 1)\n",
    "\n",
    "        # test 0: almost same as x_data but not exact.\n",
    "        # probably because hsv <-> rgb floating point ops\n",
    "        \n",
    "        # original test \n",
    "        y_pil = F.adjust_hue(x_pil, 0)\n",
    "        y_np = np.array(y_pil)\n",
    "\n",
    "        # test for torch.Tensor\n",
    "        y_tensor = adjust_hue2(x_tensor, 0)\n",
    "        y_tensor_after = torch.round(y_tensor * 255).type(torch.IntTensor).permute(1, 2, 0)\n",
    "        y_tensor_np = y_tensor_after.numpy()\n",
    "\n",
    "        y_ans = [0, 5, 13, 54, 139, 226, 35, 8, 234, 91, 255, 1]\n",
    "        y_ans = np.array(y_ans, dtype=np.uint8).reshape(x_shape)\n",
    "        \n",
    "        assert np.allclose(y_np, y_ans)\n",
    "        assert np.allclose(y_tensor_np, y_ans)\n",
    "\n",
    "\n",
    "        \n",
    "        # test 1\n",
    "        # original test \n",
    "        y_pil = adjust_hue2(x_pil, 0.25)\n",
    "        y_np = np.array(y_pil)\n",
    "        \n",
    "        # test for torch.Tensor\n",
    "        y_tensor = adjust_hue2(x_tensor, 0.25)\n",
    "        y_tensor_after = torch.round(y_tensor * 255).type(torch.IntTensor).permute(1, 2, 0)\n",
    "        y_tensor_np = y_tensor_after.numpy()\n",
    "        print(\"=====y_np:\", y_np.shape, y_np)\n",
    "        print(\"=====y_tensor_np:\",y_tensor_np)\n",
    "\n",
    "\n",
    "        \n",
    "        y_ans = [13, 0, 12, 224, 54, 226, 234, 8, 99, 1, 222, 255]\n",
    "        y_ans = np.array(y_ans, dtype=np.uint8).reshape(x_shape)\n",
    "        assert np.allclose(y_np, y_ans)\n",
    "        assert np.allclose(y_tensor_np, y_ans)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # test 2\n",
    "        # original test \n",
    "        y_pil = F.adjust_hue(x_pil, -0.25)\n",
    "        y_np = np.array(y_pil)\n",
    "        \n",
    "        # test for torch.Tensor\n",
    "        y_tensor = adjust_hue2(x_tensor, -0.25)\n",
    "        y_tensor_after = torch.round(y_tensor * 255).type(torch.IntTensor).permute(1, 2, 0)\n",
    "        y_tensor_np = y_tensor_after.numpy()\n",
    "\n",
    "        y_ans = [0, 13, 2, 54, 226, 58, 8, 234, 152, 255, 43, 1]\n",
    "        y_ans = np.array(y_ans, dtype=np.uint8).reshape(x_shape)\n",
    "        assert np.allclose(y_np, y_ans)\n",
    "        assert np.allclose(y_tensor_np, y_ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pil working\n",
      "=====y_np: (2, 2, 3) [[[ 13   0  12]\n",
      "  [224  54 226]]\n",
      "\n",
      " [[234   8  99]\n",
      "  [  1 222 255]]]\n",
      "=====y_tensor_np: [[[ 13   0  12]\n",
      "  [224  54 226]]\n",
      "\n",
      " [[234   8  98]\n",
      "  [  1 222 255]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-e3b6868c40cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_adjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-449-ae658697428d>\u001b[0m in \u001b[0;36mtest_adjust_hue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0my_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tensor_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t.test_adjust_hue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the rgb2hsv and hsv2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the testing data\n",
    "x_shape = [2, 2, 3]\n",
    "x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n",
    "x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n",
    "x_pil = Image.fromarray(x_np, mode='RGB')\n",
    "        \n",
    "transform = transforms.ToTensor()\n",
    "x_tensor = transform(x_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6000, 0.5843],\n",
      "         [0.6863, 0.2745]]])\n",
      "tensor([[[1.0000, 0.7608],\n",
      "         [0.9647, 0.9961]]])\n",
      "tensor([[[0.0510, 0.8863],\n",
      "         [0.9176, 1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# PIL: convert from RGB to HSV\n",
    "h, s, v = x_pil.convert('HSV').split()\n",
    "print(transform(h))\n",
    "print(transform(s))\n",
    "print(transform(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.2118],\n",
       "         [0.1373, 0.3569]],\n",
       "\n",
       "        [[0.0196, 0.5451],\n",
       "         [0.0314, 1.0000]],\n",
       "\n",
       "        [[0.0510, 0.8863],\n",
       "         [0.9176, 0.0039]]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PIL: convert from RGB to HSV\n",
    "\n",
    "new_img = Image.merge('HSV', (h, s, v)).convert(\"RGB\")\n",
    "new_img_tensor = transform(new_img)\n",
    "new_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.2120],\n",
       "          [0.1365, 0.3555]]],\n",
       "\n",
       "\n",
       "        [[[0.0204, 0.5452],\n",
       "          [0.0324, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0510, 0.8863],\n",
       "          [0.9176, 0.0039]]]])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our: convert from RGB to HSV\n",
    "_hsv2rgb(torch.stack((transform(h), transform(s), transform(v))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6000, 0.5843],\n",
       "          [0.6863, 0.2745]]]), tensor([[[1.0000, 0.7608],\n",
       "          [0.9647, 0.9961]]]), tensor([[[0.0510, 0.8863],\n",
       "          [0.9176, 1.0000]]]))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PIL: convert from HSV to RGB\n",
    "h, s, v = x_pil.convert('HSV').split()\n",
    "transform(h), transform(s), transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6026, 0.5882],\n",
       "         [0.6881, 0.2749]],\n",
       "\n",
       "        [[1.0000, 0.7611],\n",
       "         [0.9658, 0.9961]],\n",
       "\n",
       "        [[0.0510, 0.8863],\n",
       "         [0.9176, 1.0000]]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our: convert from HSV to RGB\n",
    "_rgb2hsv(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another method to convert RGB and HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6785063752276868, 0.20584926884139484, 0.2667)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6785]]],\n",
       "\n",
       "\n",
       "        [[[0.2058]]],\n",
       "\n",
       "\n",
       "        [[[0.2667]]]])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import colorsys\n",
    "print(colorsys.rgb_to_hsv(0.2157, 0.2118, 0.2667))\n",
    "_rgb2hsv(torch.stack((torch.Tensor([0.2157]).view(1, 1, 1), torch.Tensor([0.2118]).view(1, 1, 1), torch.Tensor([0.2667]).view(1, 1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2157, 0.2118, 0.2667)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2157]]],\n",
       "\n",
       "\n",
       "        [[[0.2118]]],\n",
       "\n",
       "\n",
       "        [[[0.2667]]]])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(colorsys.hsv_to_rgb(0.6785063752276868, 0.20584926884139484, 0.2667))\n",
    "_hsv2rgb(torch.stack((torch.Tensor([0.6785063752276868]).view(1, 1, 1), torch.Tensor([0.20584926884139484]).view(1, 1, 1), torch.Tensor([0.2667]).view(1, 1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.020400000000000015, 0.051)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0204]]],\n",
       "\n",
       "\n",
       "        [[[0.0510]]]])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(colorsys.hsv_to_rgb(0.6000, 1.0000, 0.0510))\n",
    "_hsv2rgb(torch.stack((torch.Tensor([0.6000]).view(1, 1, 1), torch.Tensor([1.0000]).view(1, 1, 1), torch.Tensor([0.0510]).view(1, 1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
